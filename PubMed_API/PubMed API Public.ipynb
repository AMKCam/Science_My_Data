{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PubMed API - International Collaborations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welcome to this tutorial! Today, we will look at using the PubMed Application Programming Interface (API) to automatically extract information from downloaded papers. PubMed is a repository of biomedical research papers run the the US National Insitite of Health: https://pubmed.ncbi.nlm.nih.gov/. More information on their API can be found here: https://www.ncbi.nlm.nih.gov/home/develop/api/.\n",
    "\n",
    "Please note that to access PubMed using the API you will need to register to obtain an access key: https://support.nlm.nih.gov/kbArticle/?pn=KA-05316.\n",
    "\n",
    "In this tutorial we will look at accessing PubMed papers which fall under the \"obesity\" search term over the last 10 years. We will extract the author information and make graphs using this information to determine who is collaborating with whom.\n",
    "\n",
    "To do this, we make some assumptions:\n",
    "1) All authors listed on the paper are assumed to have contributed to the paper and are considered working together,\n",
    "2) We identify the authors' location based on the information they provide in the paper,\n",
    "3) We remove authors who share the same country location,\n",
    "4) Authors on the same paper from different countries are assumed to be international collaborators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "%matplotlib inline\n",
    "import networkx as nx\n",
    "import difflib\n",
    "import os\n",
    "import conda\n",
    "\n",
    "\n",
    "conda_file_dir = conda.__file__\n",
    "conda_dir = conda_file_dir.split('lib')[0]\n",
    "proj_lib = os.path.join(os.path.join(conda_dir, 'share'), 'proj')\n",
    "os.environ[\"PROJ_LIB\"] = proj_lib\n",
    "\n",
    "from mpl_toolkits.basemap import Basemap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PubMed Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Biopython to make our search a bit easier. More information on Biopython can be found here: https://biopython.org/docs/1.76/api/Bio.Entrez.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note you will need to fill in your email in the code below!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search pubmed for obesity articles published in last 10 years\n",
    "Entrez.email = \"[your email here]\"\n",
    "handle = Entrez.esearch(db=\"pubmed\", term=\"obesity[biomedical]\", mindate=\"2014\",retmax=\"500\",usehistory=\"y\")\n",
    "record = Entrez.read(handle)\n",
    "idlist = record[\"IdList\"]\n",
    "handle = Entrez.efetch(db=\"pubmed\", id=idlist, rettype=\"medline\", retmode=\"text\")\n",
    "records = Medline.parse(handle)\n",
    "records = list(records)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's open record to find how many papers have been published since 2014 - our count is 490,503. That is a lot of papers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a sneak peak at the first 5 records to see how our data is stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First 5 records\n",
    "for record in records[0:5]:\n",
    "    print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting Paper Information"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our papers, we want to extract some information about them. We want to extract the location information and see which country the authors belong to. For this we make use of some text files containing a list of all the countries in the world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract countries and usa counties\n",
    "with open(\"Countries.txt\",\"r\") as f:\n",
    "    countries = f.readlines()\n",
    "f.close()\n",
    "countries = [x.strip() for x in countries]\n",
    "\n",
    "usa_counties = []\n",
    "with open(\"USA_Counties.txt\",\"r\") as f:\n",
    "    usa_counties = f.readlines()    \n",
    "f.close()\n",
    "usa_counties = [x.strip() for x in usa_counties] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice form the records information that journal type is stored under 'JT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print journal\n",
    "for record in records:\n",
    "    print(\"Journal: \", record.get(\"JT\",\"?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will notice form the records information that author location is stored under 'AD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print author location\n",
    "for record in records:\n",
    "    print(\"Author Location: \", record.get(\"AD\",\"?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert author location to dictionary\n",
    "author_location_dic = dict()\n",
    "for index,record in enumerate(records):\n",
    "    author_location = record.get(\"AD\",\"?\")\n",
    "    author_location_dic[index] = author_location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Location of authors for each paper\n",
    "final_author_location_list = []\n",
    "for value in author_location_dic.values():\n",
    "    author_country_list = []\n",
    "    for elem in value:\n",
    "        info = re.split(r'[,]', elem)[-1]\n",
    "        #print(info)\n",
    "        country_info = str(info.partition(\".\")[0])\n",
    "        #print(country_info)\n",
    "        for elem2 in countries:\n",
    "            if elem2 in country_info:\n",
    "                author_country_list.append(elem2)\n",
    "        for elem3 in usa_counties:\n",
    "            if elem3 in country_info:\n",
    "                author_country_list.append(\"United States\")\n",
    "        author_tuple = tuple(author_country_list)\n",
    "    final_author_location_list.append(author_tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove empty tuples\n",
    "final_author_location_list = [x for x in final_author_location_list if x != ()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's examine the final author location list to see the countries the authors come from. You can see many of them are from the same country! We're interested in those authors collaborating across countries. Let's do some more digging!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_author_location_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find collaborating countries\n",
    "list_collaborators = []\n",
    "for elem in final_author_location_list:\n",
    "    *collabs, origin = elem\n",
    "    #print(origin,collabs)\n",
    "    collaborators = []\n",
    "    for elem2 in collabs:\n",
    "        #print(elem2)\n",
    "        if elem2 in origin:\n",
    "            pass\n",
    "        elif elem2 != origin:\n",
    "            #print(elem2,origin)\n",
    "            if elem2 not in collaborators:\n",
    "                collaborators.append(elem2)\n",
    "    collaborators_tuple = tuple(collaborators)\n",
    "    list_collaborators.append((origin,collaborators_tuple))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove single origin countries\n",
    "final_list_collaborators = []\n",
    "for elem in list_collaborators:\n",
    "    origin, collaborators = elem\n",
    "    if collaborators != ():\n",
    "        final_list_collaborators.append((origin,collaborators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check our our final list of collaborating authors. Here you will notice that authors from the same country have been removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_list_collaborators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want our final result as a dataframe!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert list to dataframe\n",
    "origin_countries = []\n",
    "collab_countries = []\n",
    "for elem in final_list_collaborators:\n",
    "    origin, collabs = elem\n",
    "    origin_countries.append(origin)\n",
    "    #print(len(collabs))\n",
    "    collab_countries.append(list(collabs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert origin countries and collaborating countries to a dataframe\n",
    "data = {\"Origin Country\":origin_countries,\"Collaborating Countries\":collab_countries}\n",
    "collab_df = pd.DataFrame(data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reduce dimensionality for network graph\n",
    "collab_df = collab_df.explode(\"Collaborating Countries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting Our Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yay! We have a list of international collaborating countries working on Obesity. But it's not very informative having a list is it? We want a way of visualising our newly obtained information. For this next step, we utilise BaseMap to see where our collaborators are. More information on BaseMap can be found here: https://matplotlib.org/basemap/stable/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first utilise the information in our text files to see which continent a country belongs to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Countries by continent\n",
    "north_america = []\n",
    "south_america = []\n",
    "middle_east = []\n",
    "africa = []\n",
    "europe = []\n",
    "asia = []\n",
    "oceania = []\n",
    "with open(\"North_America.txt\",\"r\") as f:\n",
    "    north_america = f.readlines()\n",
    "f.close()\n",
    "north_america = [x.strip() for x in north_america]\n",
    "with open(\"South_America.txt\",\"r\") as f:\n",
    "    south_america = f.readlines() \n",
    "f.close()\n",
    "south_america = [x.strip() for x in south_america]\n",
    "with open(\"Europe.txt\",\"r\") as f:\n",
    "    europe = f.readlines()\n",
    "f.close()\n",
    "europe = [x.strip() for x in europe]\n",
    "with open(\"Africa.txt\",\"r\") as f:\n",
    "    africa = f.readlines()\n",
    "f.close()\n",
    "africa = [x.strip() for x in africa]\n",
    "with open(\"Oceania.txt\",\"r\") as f:\n",
    "    oceania = f.readlines()\n",
    "f.close()\n",
    "oceania = [x.strip() for x in oceania]\n",
    "with open(\"Middle_East.txt\",\"r\") as f:\n",
    "    middle_east = f.readlines()\n",
    "f.close()\n",
    "middle_east = [x.strip() for x in middle_east]\n",
    "with open(\"Asia.txt\",\"r\") as f:\n",
    "    asia = f.readlines()\n",
    "f.close\n",
    "asia = [x.strip() for x in asia]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to convert our list of collaborators to the origin country and their collaborators. To do this, we assume that the first country in final_list_collaborators is the origin country and subsequent countries are their collaborators. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add continent information\n",
    "def add_continent(data):\n",
    "    if data in north_america:\n",
    "        return \"North America\"\n",
    "    elif data in south_america:\n",
    "        return \"South America\"\n",
    "    elif data in europe:\n",
    "        return \"Europe\"\n",
    "    elif data in africa:\n",
    "        return \"Africa\"\n",
    "    elif data in middle_east:\n",
    "        return \"Middle East\"\n",
    "    elif data in asia:\n",
    "        return \"Asia\"\n",
    "    elif data in oceania:\n",
    "        return \"Oceania\"\n",
    "    else:\n",
    "        return \"None Given\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply continent information to our dataframe\n",
    "collab_df[\"Origin Continents\"] = collab_df[\"Origin Country\"].apply(add_continent)\n",
    "collab_df[\"Collab Continents\"] = collab_df[\"Collaborating Countries\"].apply(add_continent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can save the dataframe below for future reference!\n",
    "collab_df.to_csv(\"Internal Collabs.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first get a blank basemap\n",
    "m = Basemap(projection='robin',lon_0=0,resolution='l')\n",
    "m.drawcountries(linewidth = 0.5)\n",
    "m.fillcontinents(color='white',lake_color='white')\n",
    "m.drawcoastlines(linewidth=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our base graph\n",
    "G = nx.Graph()\n",
    "G = nx.from_pandas_edgelist(df=collab_df, source=\"Origin Country\", target=\"Collaborating Countries\", edge_attr=True, create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load geographic coordinate system for countries\n",
    "import csv\n",
    "'''\n",
    "country = [row[0].strip() for row in csv.reader(open('LonLat.csv'), delimiter=';')]    # clear spaces\n",
    "lat = [float(row[1]) for row in csv.reader(open('LonLat.csv'), delimiter=';')]\n",
    "lon = [float(row[2]) for row in csv.reader(open('LonLat.csv'), delimiter=';')]\n",
    "'''\n",
    "reader = csv.reader(open('LonLat.csv'), delimiter=';')\n",
    "\n",
    "next(reader,None)\n",
    "country=[]\n",
    "lat=[]\n",
    "lon=[]\n",
    "\n",
    "for row in reader:\n",
    "    country.append(row[0])\n",
    "    lat.append(row[1])\n",
    "    lon.append(row[2])\n",
    "    \n",
    "# define position in basemap\n",
    "position = {}\n",
    "for i in range(0, len(country)):\n",
    "    position[country[i]] = m(lon[i], lat[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the longitude and latitude for each country\n",
    "country_long_lat = pd.read_csv(\"LonLat.csv\",delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get positions for each country using the longitudes and latitudes\n",
    "position = {}\n",
    "for row in country_long_lat.itertuples():\n",
    "    position[row.Country.strip()] = (row.Longitude,row.Latitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# we remove double counts\n",
    "position[\"CROATIA\"] = position[\"CROATIA (HRVATSKA)\"]\n",
    "position.pop(\"CROATIA (HRVATSKA)\")\n",
    "position[\"SERBIA\"] = [44,21]\n",
    "position[\"SLOVAKIA\"] = position[\"SLOVAK REPUBLIC\"]\n",
    "position.pop(\"SLOVAK REPUBLIC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert position to a dictionary\n",
    "position_dic = {}\n",
    "for node in G:   \n",
    "    long, lat = position[node.upper()]\n",
    "    position_dic[node] = m(lat, long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add in general directions to our position dictionary\n",
    "position_dic[\"NW\"] = m(-180,-90)\n",
    "position_dic[\"NE\"] = m(180,90)\n",
    "position_dic[\"SW\"] = m(180,-90)\n",
    "position_dic[\"SE\"] = m(-180,90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# draw the graph!\n",
    "nx.draw_networkx_nodes(G, position_dic, nodelist = G.nodes(),node_color = 'r', alpha = 0.8, node_size = 10)\n",
    "nx.draw_networkx_edges(G, position_dic, edge_color='g',alpha=0.2, arrows = True)\n",
    "m.drawcoastlines()\n",
    "m.drawcountries()\n",
    "plt.savefig(\"International Collabs Biomedical.png\",dpi=300,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
